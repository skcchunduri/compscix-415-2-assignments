---
title: "COMPSCIX 415.2 Homework 9/Final"
author: "Chunduri SriKeerthi Chandra"
date: "Aug 10th 2018"
output: 
  html_document:
    self_contained: true
    mainfont: Arial
    theme: united
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r initilize, include=FALSE}
library(tidyverse)
library(knitr)
library(broom)
library(stats)
```

### <span style="color:Black">Exercise 1 Sampling Distributions, Functions and For Loops</span>

*Recall that the distribution of the sample mean is approximately a Normal distribution, and that the standard error is √σ/n. This holds true regardless of the distribution of our population. For this problem, assume that the number of miles that a particular car can run before its battery wears out is exponentially distributed with an average of 10,000 miles. The exponential distribution has a rate parameter that controls how quickly the distribution decays and defines what the mean and standard deviation will be. In our case the rate = 1/10000, the mean = 10000 2 and the standard deviation = 10000. You can sample from this exponential distribution in R using this code:*

```{r eval = FALSE}
# sample size
samp_size <- 100
# set the rate parameter
samp_rate <- 1/10000
# take sample
rexp(n = samp_size, rate = samp_rate)
```

```{r Initilize}
Population_sd <- 10000
```

####**STEP 1**
Write an R function that does the following:

  * Takes a sample of size samp_size from this exponential distribution (samp_size is an input parameter for the function)
  * Calculates the mean of that sample
  * Calculates the standard deviation of that sample
  * Returns the calculated mean and standard deviation as a list

```{r function}
# set the rate parameter
samp_rate <- 1/10000

mean_sd_fun <- function(sample_size) {
  # Compute random sample
  r_sample <- rexp(n = sample_size, rate = samp_rate)
  # take mean and sd of the random sample
  avg = mean(r_sample)
  sd = sd(r_sample)
  # Store the data {avg, sd} in to a list and return the list
  stats <- list(samp_avg = avg, samp_std_dev = sd)
return(stats)
}
```

####**STEP 2**
Then write a loop that does this:

  * Runs the above function 1000 times, with samp_size = 50 and samp_rate = 1/10000
  * Save all of the sample means in a vector called sample_means, and all of the sample standard deviations in a vector called sample_sds
  
```{r sample_size_50}
# No. of samples
n <- 1000
# Samples
sample_size <- 50
# Initialize empty vectors of size == 1000 for means and sds.
sample_means <- rep(NA, n)
sample_sds <- rep(NA, n)
# Take 1000 sample_averages and sample_standard_deviations
for(i in 1:n) {
  stats <- mean_sd_fun(sample_size)
  sample_means[i] <- stats$samp_avg
  sample_sds[i] <- stats$samp_std_dev
}
```

####**STEP 3**
Then

  * plot your sample means as a histogram
  * output the standard deviation of your sample means
  * calculate the theoretical standard error (σ = 10000, n = sample size)
  * calculate the mean of the sample standard deviations and use this to calculate the empirical standard error
  
```{r plots_and_calculations}
   #sample means as a histogram
   sample_means %>% as_tibble() %>% 
     ggplot(mapping = aes(x = value)) + geom_histogram(binwidth = 60) + theme_bw()
   #standard deviation of sample means
   sd(sample_means)
   #theoretical standard error
   Population_sd/sqrt(sample_size)
   #empirical standard error
   sd_mean <- mean(sample_sds)
   #Since the population standard deviation is seldom known, the standard error of the mean is usually estimated as the sample standard deviation divided by the square root of the sample size [From wiki]
   sd_mean/sqrt(sample_size)
```

####**STEP 4**
####Using a sample size of 500
```{r sample_size_500}
# No. of samples
n <- 1000
# Samples
sample_size <- 500
# Initialize empty vectors of size == 1000 for means and sds.
sample_means <- rep(NA, n)
sample_sds <- rep(NA, n)
# Take 1000 sample_averages and sample_standard_deviations
for(i in 1:n) {
  stats <- mean_sd_fun(sample_size)
  sample_means[i] <- stats$samp_avg
  sample_sds[i] <- stats$samp_std_dev
}

#sample means as a histogram
sample_means %>% as_tibble() %>% 
  ggplot(mapping = aes(x = value)) + geom_histogram(binwidth = 30) + theme_bw()
#standard deviation of sample means
sd(sample_means)
#theoretical standard error
Population_sd/sqrt(sample_size)
#empirical standard error
sd_mean <- mean(sample_sds)
#Since the population standard deviation is seldom known, the standard error of the mean is usually estimated as the sample standard deviation divided by the square root of the sample size [From wiki]
sd_mean/sqrt(sample_size)
```

####Using a sample size of 5000
```{r sample_size_5000}
# No. of samples
n <- 1000
# Samples
sample_size <- 5000
# Initialize empty vectors of size == 1000 for means and sds.
sample_means <- rep(NA, n)
sample_sds <- rep(NA, n)
# Take 1000 sample_averages and sample_standard_deviations
for(i in 1:n) {
  stats <- mean_sd_fun(sample_size)
  sample_means[i] <- stats$samp_avg
  sample_sds[i] <- stats$samp_std_dev
}

#sample means as a histogram
sample_means %>% as_tibble() %>% 
  ggplot(mapping = aes(x = value)) + geom_histogram(binwidth = 30) + theme_bw()
#standard deviation of sample means
sd(sample_means)
#theoretical standard error
Population_sd/sqrt(sample_size)
#empirical standard error
sd_mean <- mean(sample_sds)
#Since the population standard deviation is seldom known, the standard error of the mean is usually estimated as the sample standard deviation divided by the square root of the sample size [From wiki]
sd_mean/sqrt(sample_size)
```

### <span style="color:Black">Exercise 2 Linear Regression</span>
*For this exercise we will return to the House Prices prediction dataset that we used for HW 7. You should have already downloaded the train.csv dataset before, but if you didn’t you can download it from Canvas in this week’s module.*

Load the train.csv dataset into R and fit a regression model with:

  * y = SalePrice
  * Features: LotArea, OverallQual, and ExterQual

Answer these questions:

  * Use the broom package to output the coefficients and the R-squared
  * Interpret the coefficient on LotArea
  * Interpret the coefficient on ExterQualGd
  * Compare this model to the model we fit in HW 7 with GrLivArea, OverallQual, Neighborhood. Which
is the better fitting model?

```{r load_train_data, message = FALSE}
filePath <- "/Users/srchundu/UCBExtension/DataScienceIntro/compscix-415-2-assignments/Final/train.csv"
trainData <- read_csv(file = filePath)
```

```{r regrission_model}
#Regriesion model using R functions.
sales_lm <- lm(formula = SalePrice ~ LotArea + OverallQual + ExterQual, data = trainData)
tidy(sales_lm)
#R-squared
rSq <- glance(sales_lm)
rSq$adj.r.squared
```

**Interpret the coefficient on LotArea**

Increase of 1 square feet in LotArea increases SalePrice by $1.45 on average, when all other features are held constant.

**Interpret the coefficient on ExterQualGd**

ExterQual (the quality of the material on the exterior) coefficients are relative to "Excellent". So, compared to "Excellent", SalePrice of the house with "Good" exterior quality sells $71529.5 less, when all other features are held constant.

**Compare this model to the model we fit in HW 7 with GrLivArea, OverallQual, Neighborhood. Which is the better fitting model?**

Compared to current model (with features LotArea, OverallQual, and ExterQual), the model used in HW 7 is practically significant because of Neighborhood feature. Neighborhood has long been a strong factor for house prices. A model with OverallQual, Neighborhood and LotArea would be much better though.

### <span style="color:Black">Exercise 3 AB Testing</span>

*Download the ab_test_data.csv file from Canvas. This file contains two columns: version and conversion. Each row is a visitor to a webpage. The version column tells us which version of the webpage the visitor saw, and the conversion column is a binary value and equals 1 if the visitor converted (0 otherwise). We want to perform an AB test on this data to see if the conversion rates are different for the two versions of the webpage.*

Answer these questions:

  a. What proportion of visitors converted for each version of the webpage?
  b. Perform the AB test in R. What is the p-value for the AB test (hypothesis test of proportions)?

```{r load_ab_test_data, message = FALSE}
filePath <- "/Users/srchundu/UCBExtension/DataScienceIntro/compscix-415-2-assignments/Final/ab_test_data.csv"
abtestData <- read_csv(file = filePath)
```

```{r summarize_test_data}
#Summarize test data and calculate propotion
(summarizedData <- abtestData %>% group_by(version) %>% summarise(tatal_visited = n(), total_converged = sum(conversion), propotion = total_converged/tatal_visited))
```

```{r abtest}
#Perform the AB test in R. What is the p-value for the AB test (hypothesis test of proportions)
prop_test <- prop.test(summarizedData$total_converged, summarizedData$tatal_visited)
prop_test$p.value
```

The p-value is **`r prop_test$p.value` i.e p-value < α**. It can be concluded that the conversion rates for Version A and B are significantly different than each other.
